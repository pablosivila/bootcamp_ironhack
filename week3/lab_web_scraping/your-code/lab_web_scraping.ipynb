{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure you have all libraries installed before start the lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "# from pprint import pprint\n",
    "# from lxml import html\n",
    "# from lxml.html import fromstring\n",
    "# import urllib.request\n",
    "# from urllib.request import urlopen\n",
    "import random\n",
    "import re\n",
    "# import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# requests:\n",
    "\"Requests is one of the most downloaded Python packages of all time, pulling in over 400,000 downloads each day. Join the party!\"\n",
    "\n",
    "[Source](https://2.python-requests.org/en/master/)\n",
    "\n",
    "##### internal jokes:\n",
    "\"Requests is the only Non-GMO HTTP library for Python, safe for human consumption.\" #3556\n",
    "[Source](https://github.com/kennethreitz/requests/issues/3556)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[type(item) for item in list(soup.children)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=soup.find_all('h1', class_=\"h3 lh-condensed\")\n",
    "a = [elem.text.strip().split(\"\\n\") for elem in a]\n",
    "a1=[\"\".join(elem) for elem in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['文翼',\n",
       " 'Daniel Wirtz',\n",
       " 'Arvid Norberg',\n",
       " 'Ran Luo',\n",
       " 'James Newton-King',\n",
       " 'Sebastián Ramírez',\n",
       " 'XhmikosR',\n",
       " 'Adam Scarr',\n",
       " 'Lipis',\n",
       " 'Lee Dohm',\n",
       " 'holger krekel',\n",
       " 'Benjamin Peterson',\n",
       " 'Manu MA',\n",
       " 'Niels Lohmann',\n",
       " 'Andrew Svetlov',\n",
       " 'Krzysztof Magiera',\n",
       " 'Swapnil Agarwal',\n",
       " 'Jeffrey Su',\n",
       " 'Jack Lloyd',\n",
       " 'Mr.doob',\n",
       " 'David Desmaisons',\n",
       " 'Rakan Nimer',\n",
       " 'Sebastian Raschka',\n",
       " 'Stefan Prodan',\n",
       " 'Ben McCann']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url2 = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "page2 = requests.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(page2.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(soup2.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=soup2.find_all('h1', class_=\"h3 lh-condensed\")\n",
    "b = [elem.text.strip().replace(\" \",\"\").split(\"\\n\") for elem in b]\n",
    "b1=[\"\".join(elem) for elem in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['axi0mX/ipwndfu',\n",
       " 'svip-lab/impersonator',\n",
       " 'geekcomputers/Python',\n",
       " 'brightmart/albert_zh',\n",
       " '521xueweihan/HelloGitHub',\n",
       " 'huggingface/transformers',\n",
       " 'SQRPI/JiaGuoMeng',\n",
       " 'nvbn/thefuck',\n",
       " 'pielco11/fav-up',\n",
       " 'CoreyMSchafer/code_snippets',\n",
       " 'testerSunshine/12306',\n",
       " 'donnemartin/system-design-primer',\n",
       " 'Avik-Jain/100-Days-Of-ML-Code',\n",
       " 'tie1r1/checkm8gui',\n",
       " 'pallets/flask',\n",
       " 'anishathalye/neural-style',\n",
       " 'ytdl-org/youtube-dl',\n",
       " 'ildoonet/tf-pose-estimation',\n",
       " 'Nyloner/Nyspider',\n",
       " 'wangzheng0822/algo',\n",
       " 'twintproject/twint',\n",
       " 'hamuchiwa/AutoRCCar',\n",
       " 'Kr1s77/awesome-python-login-model',\n",
       " 'microsoft/c9-python-getting-started',\n",
       " 'pi-hole/docker-pi-hole']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url3 = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "page3 = requests.get(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup3 = BeautifulSoup(page3.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(soup3.children)\n",
    "#soup3.find_all(\"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/en/thumb/1/1b/Semi-protection-shackle.svg/20px-Semi-protection-shackle.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Newman_Laugh-O-Gram_%281921%29.webm/220px-seek%3D2-Newman_Laugh-O-Gram_%281921%29.webm.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/170px-Trolley_Troubles_poster.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/7/71/Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg/170px-Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/170px-Steamboat-willie.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/170px-Walt_Disney_1935.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/170px-Walt_Disney_Grave.JPG',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg/170px-Roy_O._Disney_with_Company_at_Press_Conference.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Disney_Display_Case.JPG/170px-Disney_Display_Case.JPG',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/30px-Animation_disc.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/29px-P_vip.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/24px-Magic_Kingdom_castle.jpg',\n",
       " 'upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/30px-Video-x-generic.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/30px-Flag_of_Los_Angeles_County%2C_California.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/30px-Blank_television_set.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/30px-Flag_of_the_United_States.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/22px-Commons-logo.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/25px-Wikiquote-logo.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Wikidata-logo.svg/30px-Wikidata-logo.svg.png',\n",
       " 'upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " 'en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1',\n",
       " 'static/images/wikimedia-button.png',\n",
       " 'static/images/poweredby_mediawiki_88x31.png']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=soup3.find_all(\"img\")\n",
    "c=[elem['src'] for elem in c]\n",
    "c1 = [elem.strip(\"/\") for elem in c]\n",
    "c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url4 ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "page4 = requests.get(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup4 = BeautifulSoup(page4.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(soup4.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=[elem.get('href') for elem in soup4.find_all('a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.remove(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://wikipedia.com/wiki/Pythonidae',\n",
       " 'http://wikipedia.com/wiki/Python_(genus)',\n",
       " 'http://wikipedia.com/wiki/Python_(mythology)',\n",
       " 'http://wikipedia.com/wiki/Python_of_Aenus',\n",
       " 'http://wikipedia.com/wiki/Python_(painter)',\n",
       " 'http://wikipedia.com/wiki/Python_of_Byzantium',\n",
       " 'http://wikipedia.com/wiki/Python_of_Catana',\n",
       " 'http://wikipedia.com/wiki/Python_(film)',\n",
       " 'http://wikipedia.com/wiki/Pythons_2',\n",
       " 'http://wikipedia.com/wiki/Monty_Python',\n",
       " 'http://wikipedia.com/wiki/Python_(Monty)_Pictures',\n",
       " 'http://wikipedia.com/wiki/Python_(programming_language)',\n",
       " 'http://wikipedia.com/wiki/CPython',\n",
       " 'http://wikipedia.com/wiki/CMU_Common_Lisp',\n",
       " 'http://wikipedia.com/wiki/Python_(Busch_Gardens_Tampa_Bay)',\n",
       " 'http://wikipedia.com/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)',\n",
       " 'http://wikipedia.com/wiki/Python_(Efteling)',\n",
       " 'http://wikipedia.com/wiki/Python_(automobile_maker)',\n",
       " 'http://wikipedia.com/wiki/Python_(Ford_prototype)',\n",
       " 'http://wikipedia.com/wiki/Colt_Python',\n",
       " 'http://wikipedia.com/wiki/Python_(missile)',\n",
       " 'http://wikipedia.com/wiki/Python_(nuclear_primary)',\n",
       " 'http://wikipedia.com/wiki/Python_Anghelo',\n",
       " 'http://wikipedia.com/wiki/PYTHON',\n",
       " 'http://wikipedia.com/wiki/Cython',\n",
       " 'http://wikipedia.com/wiki/Pyton',\n",
       " 'http://wikipedia.com/wiki/File:Disambig_gray.svg',\n",
       " 'http://wikipedia.com/wiki/Help:Disambiguation',\n",
       " 'http://wikipedia.com/wiki/Help:Category',\n",
       " 'http://wikipedia.com/wiki/Category:Disambiguation_pages',\n",
       " 'http://wikipedia.com/wiki/Category:Disambiguation_pages_with_short_description',\n",
       " 'http://wikipedia.com/wiki/Category:All_article_disambiguation_pages',\n",
       " 'http://wikipedia.com/wiki/Category:All_disambiguation_pages',\n",
       " 'http://wikipedia.com/wiki/Category:Animal_common_name_disambiguation_pages',\n",
       " 'http://wikipedia.com/wiki/Special:MyTalk',\n",
       " 'http://wikipedia.com/wiki/Special:MyContributions',\n",
       " 'http://wikipedia.com/wiki/Python',\n",
       " 'http://wikipedia.com/wiki/Talk:Python',\n",
       " 'http://wikipedia.com/wiki/Python',\n",
       " 'http://wikipedia.com/wiki/Main_Page',\n",
       " 'http://wikipedia.com/wiki/Main_Page',\n",
       " 'http://wikipedia.com/wiki/Portal:Contents',\n",
       " 'http://wikipedia.com/wiki/Portal:Featured_content',\n",
       " 'http://wikipedia.com/wiki/Portal:Current_events',\n",
       " 'http://wikipedia.com/wiki/Special:Random',\n",
       " 'http://wikipedia.com/wiki/Help:Contents',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:About',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:Community_portal',\n",
       " 'http://wikipedia.com/wiki/Special:RecentChanges',\n",
       " 'http://wikipedia.com/wiki/Special:WhatLinksHere/Python',\n",
       " 'http://wikipedia.com/wiki/Special:RecentChangesLinked/Python',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:File_Upload_Wizard',\n",
       " 'http://wikipedia.com/wiki/Special:SpecialPages',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:About',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:General_disclaimer']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1=[]\n",
    "for elem in d:\n",
    "    if '#' not in elem:\n",
    "        if 'https' not in elem:\n",
    "            if 'index' not in elem:\n",
    "                if '//' not in elem:\n",
    "                    d1.append(\"http://wikipedia.com\"+elem)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://wikipedia.com/wiki/Python_(automobile_maker)\n"
     ]
    }
   ],
   "source": [
    "url4_2=random.choice(d1)\n",
    "print(url4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "page4_2 = requests.get(url4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup4_2 = BeautifulSoup(page4_2.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2=[elem.get('href') for elem in soup4_2.find_all('a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " '#mw-head',\n",
       " '#p-search',\n",
       " '/wiki/AC_Cobra',\n",
       " '/wiki/Python_Automobile',\n",
       " '/wiki/Riverside,_California',\n",
       " '/wiki/Fort_Collins,_Colorado',\n",
       " '/w/index.php?title=Python_(automobile_maker)&action=edit&section=1',\n",
       " '/wiki/File:Question_book-new.svg',\n",
       " '/wiki/Wikipedia:Citing_sources',\n",
       " '/wiki/Wikipedia:Verifiability',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python_(automobile_maker)&action=edit',\n",
       " '/wiki/Help:Introduction_to_referencing_with_Wiki_Markup/1',\n",
       " '/wiki/Wikipedia:Verifiability#Burden_of_evidence',\n",
       " '/wiki/Help:Maintenance_template_removal',\n",
       " '/wiki/File:De_facto_car.svg',\n",
       " '/wiki/Wikipedia:Stub',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python_(automobile_maker)&action=edit',\n",
       " '/wiki/Template:Motorvehicle-company-stub',\n",
       " '/wiki/Template_talk:Motorvehicle-company-stub',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Template:Motorvehicle-company-stub&action=edit',\n",
       " '/wiki/File:AusFactory.svg',\n",
       " '/wiki/Wikipedia:Stub',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python_(automobile_maker)&action=edit',\n",
       " '/wiki/Template:Australia-company-stub',\n",
       " '/wiki/Template_talk:Australia-company-stub',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Template:Australia-company-stub&action=edit',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python_(automobile_maker)&oldid=909523166',\n",
       " '/wiki/Help:Category',\n",
       " '/wiki/Category:Car_manufacturers_of_Australia',\n",
       " '/wiki/Category:Motor_vehicle_company_stubs',\n",
       " '/wiki/Category:Australian_company_stubs',\n",
       " '/wiki/Category:Use_dmy_dates_from_July_2019',\n",
       " '/wiki/Category:Articles_lacking_sources_from_December_2009',\n",
       " '/wiki/Category:All_articles_lacking_sources',\n",
       " '/wiki/Category:All_stub_articles',\n",
       " '/wiki/Special:MyTalk',\n",
       " '/wiki/Special:MyContributions',\n",
       " '/w/index.php?title=Special:CreateAccount&returnto=Python+%28automobile+maker%29',\n",
       " '/w/index.php?title=Special:UserLogin&returnto=Python+%28automobile+maker%29',\n",
       " '/wiki/Python_(automobile_maker)',\n",
       " '/wiki/Talk:Python_(automobile_maker)',\n",
       " '/wiki/Python_(automobile_maker)',\n",
       " '/w/index.php?title=Python_(automobile_maker)&action=edit',\n",
       " '/w/index.php?title=Python_(automobile_maker)&action=history',\n",
       " '/wiki/Main_Page',\n",
       " '/wiki/Main_Page',\n",
       " '/wiki/Portal:Contents',\n",
       " '/wiki/Portal:Featured_content',\n",
       " '/wiki/Portal:Current_events',\n",
       " '/wiki/Special:Random',\n",
       " 'https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en',\n",
       " '//shop.wikimedia.org',\n",
       " '/wiki/Help:Contents',\n",
       " '/wiki/Wikipedia:About',\n",
       " '/wiki/Wikipedia:Community_portal',\n",
       " '/wiki/Special:RecentChanges',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Contact_us',\n",
       " '/wiki/Special:WhatLinksHere/Python_(automobile_maker)',\n",
       " '/wiki/Special:RecentChangesLinked/Python_(automobile_maker)',\n",
       " '/wiki/Wikipedia:File_Upload_Wizard',\n",
       " '/wiki/Special:SpecialPages',\n",
       " '/w/index.php?title=Python_(automobile_maker)&oldid=909523166',\n",
       " '/w/index.php?title=Python_(automobile_maker)&action=info',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q7263920',\n",
       " '/w/index.php?title=Special:CiteThisPage&page=Python_%28automobile_maker%29&id=909523166',\n",
       " '/w/index.php?title=Special:Book&bookcmd=book_creator&referer=Python+%28automobile+maker%29',\n",
       " '/w/index.php?title=Special:ElectronPdf&page=Python+%28automobile+maker%29&action=show-download-screen',\n",
       " '/w/index.php?title=Python_(automobile_maker)&printable=yes',\n",
       " 'https://de.wikipedia.org/wiki/Python_Vehicles_Australia',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q7263920#sitelinks-wikipedia',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License',\n",
       " '//creativecommons.org/licenses/by-sa/3.0/',\n",
       " '//foundation.wikimedia.org/wiki/Terms_of_Use',\n",
       " '//foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " '//www.wikimediafoundation.org/',\n",
       " 'https://foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " '/wiki/Wikipedia:About',\n",
       " '/wiki/Wikipedia:General_disclaimer',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Contact_us',\n",
       " 'https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute',\n",
       " 'https://foundation.wikimedia.org/wiki/Cookie_statement',\n",
       " '//en.m.wikipedia.org/w/index.php?title=Python_(automobile_maker)&mobileaction=toggle_view_mobile',\n",
       " 'https://wikimediafoundation.org/',\n",
       " 'https://www.mediawiki.org/']"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.remove(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://wikipedia.com/wiki/AC_Cobra',\n",
       " 'http://wikipedia.com/wiki/Python_Automobile',\n",
       " 'http://wikipedia.com/wiki/Riverside,_California',\n",
       " 'http://wikipedia.com/wiki/Fort_Collins,_Colorado',\n",
       " 'http://wikipedia.com/wiki/File:Question_book-new.svg',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:Citing_sources',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:Verifiability',\n",
       " 'http://wikipedia.com/wiki/Help:Introduction_to_referencing_with_Wiki_Markup/1',\n",
       " 'http://wikipedia.com/wiki/Help:Maintenance_template_removal',\n",
       " 'http://wikipedia.com/wiki/File:De_facto_car.svg',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:Stub',\n",
       " 'http://wikipedia.com/wiki/Template:Motorvehicle-company-stub',\n",
       " 'http://wikipedia.com/wiki/Template_talk:Motorvehicle-company-stub',\n",
       " 'http://wikipedia.com/wiki/File:AusFactory.svg',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:Stub',\n",
       " 'http://wikipedia.com/wiki/Template:Australia-company-stub',\n",
       " 'http://wikipedia.com/wiki/Template_talk:Australia-company-stub',\n",
       " 'http://wikipedia.com/wiki/Help:Category',\n",
       " 'http://wikipedia.com/wiki/Category:Car_manufacturers_of_Australia',\n",
       " 'http://wikipedia.com/wiki/Category:Motor_vehicle_company_stubs',\n",
       " 'http://wikipedia.com/wiki/Category:Australian_company_stubs',\n",
       " 'http://wikipedia.com/wiki/Category:Use_dmy_dates_from_July_2019',\n",
       " 'http://wikipedia.com/wiki/Category:Articles_lacking_sources_from_December_2009',\n",
       " 'http://wikipedia.com/wiki/Category:All_articles_lacking_sources',\n",
       " 'http://wikipedia.com/wiki/Category:All_stub_articles',\n",
       " 'http://wikipedia.com/wiki/Special:MyTalk',\n",
       " 'http://wikipedia.com/wiki/Special:MyContributions',\n",
       " 'http://wikipedia.com/wiki/Python_(automobile_maker)',\n",
       " 'http://wikipedia.com/wiki/Talk:Python_(automobile_maker)',\n",
       " 'http://wikipedia.com/wiki/Python_(automobile_maker)',\n",
       " 'http://wikipedia.com/wiki/Main_Page',\n",
       " 'http://wikipedia.com/wiki/Main_Page',\n",
       " 'http://wikipedia.com/wiki/Portal:Contents',\n",
       " 'http://wikipedia.com/wiki/Portal:Featured_content',\n",
       " 'http://wikipedia.com/wiki/Portal:Current_events',\n",
       " 'http://wikipedia.com/wiki/Special:Random',\n",
       " 'http://wikipedia.com/wiki/Help:Contents',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:About',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:Community_portal',\n",
       " 'http://wikipedia.com/wiki/Special:RecentChanges',\n",
       " 'http://wikipedia.com/wiki/Special:WhatLinksHere/Python_(automobile_maker)',\n",
       " 'http://wikipedia.com/wiki/Special:RecentChangesLinked/Python_(automobile_maker)',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:File_Upload_Wizard',\n",
       " 'http://wikipedia.com/wiki/Special:SpecialPages',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:About',\n",
       " 'http://wikipedia.com/wiki/Wikipedia:General_disclaimer']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3=[]\n",
    "for elem in d2:\n",
    "    if '#' not in elem:\n",
    "        if 'https' not in elem:\n",
    "            if 'index' not in elem:\n",
    "                if '//' not in elem:\n",
    "                    d3.append(\"http://wikipedia.com\"+elem)\n",
    "d3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url5 = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "page5 = requests.get(url5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup5 = BeautifulSoup(page5.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title 19 - Customs Duties', 'Title 23 - Highways ٭']"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e=soup5.find_all('div', class_=\"usctitlechanged\")\n",
    "e = [elem.text.strip().split(\"\\n\") for elem in e]\n",
    "e1=[\"\".join(elem) for elem in e]\n",
    "e1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url6 = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "page6 = requests.get(url6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup6 = BeautifulSoup(page6.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'ARNOLDO JIMENEZ',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'YASER ABDEL SAID',\n",
       " 'JASON DEREK BROWN',\n",
       " 'ALEXIS FLORES',\n",
       " 'EUGENE PALMER',\n",
       " 'SANTIAGO VILLALBA MEDEROS',\n",
       " 'RAFAEL CARO-QUINTERO',\n",
       " 'ROBERT WILLIAM FISHER']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=soup6.find_all('h3', class_=\"title\")\n",
    "f = [elem.text.strip().split(\"\\n\") for elem in f]\n",
    "f1=[\"\".join(elem) for elem in f]\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almost there -- the last one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url7 = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3be2f123bf4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpage7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "page7 = requests.get(url7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup7 = BeautifulSoup(page7.content, 'lxml')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g=soup7.find_all('a')\n",
    "g = [elem.text.strip().split(\"\\n\") for elem in g]\n",
    "g=[\"\".join(elem) for elem in g]\n",
    "\n",
    "date_time=[]\n",
    "for elem in g:\n",
    "    if '2019' in elem:\n",
    "        date_time.append(re.sub(\".[\\xa0\\xa0\\xa0].\", \"\", elem))\n",
    "        \n",
    "\n",
    "#tentando fazer uma coluna por vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup7' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-56a448f633b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\xa0\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'soup7' is not defined"
     ]
    }
   ],
   "source": [
    "rows = soup7.find_all('tr')\n",
    "rows = [row.text.strip().split(\"\\xa0\") for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>set_server_date(2019,10,1,20,0,52)\\nCurrent ti...</td>\n",
       "      <td>Member access\\n\\nName</td>\n",
       "      <td>\\n\\n\\nPwd</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Member access</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Name</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>earthquake2019-10-01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>09:23:30.010hr 37min ago9.02</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>83.79</td>\n",
       "      <td>W</td>\n",
       "      <td></td>\n",
       "      <td>37 M3.8</td>\n",
       "      <td>COSTA RICA2019-10-01 16:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>earthquake2019-10-01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>09:15:46.810hr 45min ago54.20</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>164.75</td>\n",
       "      <td>W</td>\n",
       "      <td></td>\n",
       "      <td>71mb4.2</td>\n",
       "      <td>UNIMAK ISLAND REGION, ALASKA2019-10-01 10:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0                      1  \\\n",
       "0   set_server_date(2019,10,1,20,0,52)\\nCurrent ti...  Member access\\n\\nName   \n",
       "1                                       Member access                   None   \n",
       "2                                                                       None   \n",
       "3                                                Name                   None   \n",
       "4                                                                       None   \n",
       "..                                                ...                    ...   \n",
       "62                               earthquake2019-10-01                          \n",
       "63                               earthquake2019-10-01                          \n",
       "64                                                                      None   \n",
       "65                                      12345678910»                   None   \n",
       "66                                                                      None   \n",
       "\n",
       "            2                              3     4     5       6     7     8  \\\n",
       "0   \\n\\n\\nPwd                           None  None  None    None  None  None   \n",
       "1        None                           None  None  None    None  None  None   \n",
       "2        None                           None  None  None    None  None  None   \n",
       "3        None                           None  None  None    None  None  None   \n",
       "4        None                           None  None  None    None  None  None   \n",
       "..        ...                            ...   ...   ...     ...   ...   ...   \n",
       "62              09:23:30.010hr 37min ago9.02     N         83.79     W         \n",
       "63             09:15:46.810hr 45min ago54.20     N        164.75     W         \n",
       "64       None                           None  None  None    None  None  None   \n",
       "65       None                           None  None  None    None  None  None   \n",
       "66       None                           None  None  None    None  None  None   \n",
       "\n",
       "          9                                            10  \n",
       "0      None                                          None  \n",
       "1      None                                          None  \n",
       "2      None                                          None  \n",
       "3      None                                          None  \n",
       "4      None                                          None  \n",
       "..      ...                                           ...  \n",
       "62  37 M3.8                    COSTA RICA2019-10-01 16:05  \n",
       "63  71mb4.2  UNIMAK ISLAND REGION, ALASKA2019-10-01 10:08  \n",
       "64     None                                          None  \n",
       "65     None                                          None  \n",
       "66     None                                          None  \n",
       "\n",
       "[67 rows x 11 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = rows\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>earthquake2019-10-01</td>\n",
       "      <td>19:39:42.721min ago19.20</td>\n",
       "      <td>N</td>\n",
       "      <td>155.44</td>\n",
       "      <td>W</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII2019-10-01 19:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>earthquake2019-10-01</td>\n",
       "      <td>19:39:30.021min ago9.98</td>\n",
       "      <td>N</td>\n",
       "      <td>83.63</td>\n",
       "      <td>W</td>\n",
       "      <td>COSTA RICA2019-10-01 19:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>earthquake2019-10-01</td>\n",
       "      <td>19:23:47.037min ago23.61</td>\n",
       "      <td>S</td>\n",
       "      <td>67.30</td>\n",
       "      <td>W</td>\n",
       "      <td>ANTOFAGASTA, CHILE2019-10-01 19:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>earthquake2019-10-01</td>\n",
       "      <td>19:09:19.351min ago43.18</td>\n",
       "      <td>N</td>\n",
       "      <td>3.98</td>\n",
       "      <td>E</td>\n",
       "      <td>NEAR SOUTH COAST OF FRANCE2019-10-01 19:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>earthquake2019-10-01</td>\n",
       "      <td>19:06:11.954min ago35.92</td>\n",
       "      <td>N</td>\n",
       "      <td>117.71</td>\n",
       "      <td>W</td>\n",
       "      <td>CENTRAL CALIFORNIA2019-10-01 19:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                         3  4       6  7   \\\n",
       "0  earthquake2019-10-01  19:39:42.721min ago19.20  N  155.44  W   \n",
       "1  earthquake2019-10-01   19:39:30.021min ago9.98  N   83.63  W   \n",
       "2  earthquake2019-10-01  19:23:47.037min ago23.61  S   67.30  W   \n",
       "3  earthquake2019-10-01  19:09:19.351min ago43.18  N    3.98  E   \n",
       "4  earthquake2019-10-01  19:06:11.954min ago35.92  N  117.71  W   \n",
       "\n",
       "                                           10  \n",
       "0    ISLAND OF HAWAII, HAWAII2019-10-01 19:42  \n",
       "1                  COSTA RICA2019-10-01 19:55  \n",
       "2          ANTOFAGASTA, CHILE2019-10-01 19:44  \n",
       "3  NEAR SOUTH COAST OF FRANCE2019-10-01 19:25  \n",
       "4          CENTRAL CALIFORNIA2019-10-01 19:12  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([1], axis=1, inplace = True)\n",
    "df.drop([2], axis=1, inplace = True)\n",
    "df.drop([5], axis=1, inplace = True)\n",
    "df.drop([8], axis=1, inplace = True)\n",
    "df.drop([9], axis=1, inplace = True)\n",
    "df.dropna(inplace = True)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(['index'], axis=1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['Date & Time', 'Latitude', 'Longitude', '','','Region name']\n",
    "\n",
    "df.columns=colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date &amp; Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Region name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>earthquake2019-10-01</td>\n",
       "      <td>19:39:42.721min ago19.20</td>\n",
       "      <td>N</td>\n",
       "      <td>155.44</td>\n",
       "      <td>W</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII2019-10-01 19:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>earthquake2019-10-01</td>\n",
       "      <td>19:39:30.021min ago9.98</td>\n",
       "      <td>N</td>\n",
       "      <td>83.63</td>\n",
       "      <td>W</td>\n",
       "      <td>COSTA RICA2019-10-01 19:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>earthquake2019-10-01</td>\n",
       "      <td>19:23:47.037min ago23.61</td>\n",
       "      <td>S</td>\n",
       "      <td>67.30</td>\n",
       "      <td>W</td>\n",
       "      <td>ANTOFAGASTA, CHILE2019-10-01 19:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>earthquake2019-10-01</td>\n",
       "      <td>19:09:19.351min ago43.18</td>\n",
       "      <td>N</td>\n",
       "      <td>3.98</td>\n",
       "      <td>E</td>\n",
       "      <td>NEAR SOUTH COAST OF FRANCE2019-10-01 19:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>earthquake2019-10-01</td>\n",
       "      <td>19:06:11.954min ago35.92</td>\n",
       "      <td>N</td>\n",
       "      <td>117.71</td>\n",
       "      <td>W</td>\n",
       "      <td>CENTRAL CALIFORNIA2019-10-01 19:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date & Time                  Latitude Longitude             \\\n",
       "0  earthquake2019-10-01  19:39:42.721min ago19.20         N  155.44  W   \n",
       "1  earthquake2019-10-01   19:39:30.021min ago9.98         N   83.63  W   \n",
       "2  earthquake2019-10-01  19:23:47.037min ago23.61         S   67.30  W   \n",
       "3  earthquake2019-10-01  19:09:19.351min ago43.18         N    3.98  E   \n",
       "4  earthquake2019-10-01  19:06:11.954min ago35.92         N  117.71  W   \n",
       "\n",
       "                                  Region name  \n",
       "0    ISLAND OF HAWAII, HAWAII2019-10-01 19:42  \n",
       "1                  COSTA RICA2019-10-01 19:55  \n",
       "2          ANTOFAGASTA, CHILE2019-10-01 19:44  \n",
       "3  NEAR SOUTH COAST OF FRANCE2019-10-01 19:25  \n",
       "4          CENTRAL CALIFORNIA2019-10-01 19:12  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace( { r\"\\w*earthquake\": '' }, inplace= True, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}','',regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time\"]=[y[0] for y in df[\"Latitude\"].str.split(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Latitude\"]=[y[-1] for y in df[\"Latitude\"].str.split(\"ago\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date & Time\"]=df[\"Date & Time\"]+\" \"+df[\"Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames2 = ['Date & Time', 'Latitude', 'N', 'Longitude','N1','Region name','Time']\n",
    "\n",
    "df.columns=colnames2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Latitude\"]=df[\"Latitude\"]+\" \"+df[\"N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Longitude\"]=df[\"Longitude\"]+\" \"+df[\"N1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"N\"], axis=1, inplace = True)\n",
    "df.drop([\"N1\"], axis=1, inplace = True)\n",
    "df.drop([\"Time\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date &amp; Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Region name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-01 19:39:42</td>\n",
       "      <td>19.20 N</td>\n",
       "      <td>155.44 W</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-01 19:39:30</td>\n",
       "      <td>9.98 N</td>\n",
       "      <td>83.63 W</td>\n",
       "      <td>COSTA RICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-01 19:23:47</td>\n",
       "      <td>23.61 S</td>\n",
       "      <td>67.30 W</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-01 19:09:19</td>\n",
       "      <td>43.18 N</td>\n",
       "      <td>3.98 E</td>\n",
       "      <td>NEAR SOUTH COAST OF FRANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-01 19:06:11</td>\n",
       "      <td>35.92 N</td>\n",
       "      <td>117.71 W</td>\n",
       "      <td>CENTRAL CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-01 19:03:51</td>\n",
       "      <td>36.09 N</td>\n",
       "      <td>117.87 W</td>\n",
       "      <td>CENTRAL CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-01 18:48:42</td>\n",
       "      <td>24.16 S</td>\n",
       "      <td>67.19 W</td>\n",
       "      <td>SALTA, ARGENTINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-01 18:21:26</td>\n",
       "      <td>19.34 N</td>\n",
       "      <td>155.11 W</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2019-10-01 18:01:52</td>\n",
       "      <td>22.39 S</td>\n",
       "      <td>68.54 W</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2019-10-01 17:43:42</td>\n",
       "      <td>56.40 N</td>\n",
       "      <td>148.85 W</td>\n",
       "      <td>GULF OF ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2019-10-01 17:20:27</td>\n",
       "      <td>38.78 N</td>\n",
       "      <td>27.38 E</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2019-10-01 16:34:11</td>\n",
       "      <td>18.46 N</td>\n",
       "      <td>70.27 W</td>\n",
       "      <td>DOMINICAN REPUBLIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2019-10-01 16:32:44</td>\n",
       "      <td>61.76 N</td>\n",
       "      <td>149.87 W</td>\n",
       "      <td>SOUTHERN ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2019-10-01 16:32:27</td>\n",
       "      <td>18.48 N</td>\n",
       "      <td>70.26 W</td>\n",
       "      <td>DOMINICAN REPUBLIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2019-10-01 16:29:23</td>\n",
       "      <td>47.38 N</td>\n",
       "      <td>120.96 W</td>\n",
       "      <td>WASHINGTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2019-10-01 16:24:38</td>\n",
       "      <td>35.92 N</td>\n",
       "      <td>30.50 E</td>\n",
       "      <td>EASTERN MEDITERRANEAN SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2019-10-01 15:51:44</td>\n",
       "      <td>18.54 N</td>\n",
       "      <td>69.64 W</td>\n",
       "      <td>DOMINICAN REPUBLIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2019-10-01 15:45:56</td>\n",
       "      <td>35.91 N</td>\n",
       "      <td>98.52 W</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2019-10-01 15:34:06</td>\n",
       "      <td>40.87 N</td>\n",
       "      <td>28.30 E</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2019-10-01 15:19:23</td>\n",
       "      <td>15.96 N</td>\n",
       "      <td>98.44 W</td>\n",
       "      <td>OFFSHORE OAXACA, MEXICO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date & Time Latitude Longitude                 Region name\n",
       "0   2019-10-01 19:39:42  19.20 N  155.44 W    ISLAND OF HAWAII, HAWAII\n",
       "1   2019-10-01 19:39:30   9.98 N   83.63 W                  COSTA RICA\n",
       "2   2019-10-01 19:23:47  23.61 S   67.30 W          ANTOFAGASTA, CHILE\n",
       "3   2019-10-01 19:09:19  43.18 N    3.98 E  NEAR SOUTH COAST OF FRANCE\n",
       "4   2019-10-01 19:06:11  35.92 N  117.71 W          CENTRAL CALIFORNIA\n",
       "5   2019-10-01 19:03:51  36.09 N  117.87 W          CENTRAL CALIFORNIA\n",
       "6   2019-10-01 18:48:42  24.16 S   67.19 W            SALTA, ARGENTINA\n",
       "7   2019-10-01 18:21:26  19.34 N  155.11 W    ISLAND OF HAWAII, HAWAII\n",
       "8   2019-10-01 18:01:52  22.39 S   68.54 W          ANTOFAGASTA, CHILE\n",
       "9   2019-10-01 17:43:42  56.40 N  148.85 W              GULF OF ALASKA\n",
       "10  2019-10-01 17:20:27  38.78 N   27.38 E              WESTERN TURKEY\n",
       "11  2019-10-01 16:34:11  18.46 N   70.27 W          DOMINICAN REPUBLIC\n",
       "12  2019-10-01 16:32:44  61.76 N  149.87 W             SOUTHERN ALASKA\n",
       "13  2019-10-01 16:32:27  18.48 N   70.26 W          DOMINICAN REPUBLIC\n",
       "14  2019-10-01 16:29:23  47.38 N  120.96 W                  WASHINGTON\n",
       "15  2019-10-01 16:24:38  35.92 N   30.50 E   EASTERN MEDITERRANEAN SEA\n",
       "16  2019-10-01 15:51:44  18.54 N   69.64 W          DOMINICAN REPUBLIC\n",
       "17  2019-10-01 15:45:56  35.91 N   98.52 W                    OKLAHOMA\n",
       "18  2019-10-01 15:34:06  40.87 N   28.30 E              WESTERN TURKEY\n",
       "19  2019-10-01 15:19:23  15.96 N   98.44 W     OFFSHORE OAXACA, MEXICO"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
